# Flower-Classification-Using-ViT
In this project, a Vision Transformer (ViT) model was implemented for flower classification based on image data. The goal was to leverage transformer-based architectures to efficiently extract visual features and classify different flower species. By utilizing the self-attention mechanism of ViT, the model effectively captured spatial dependencies in images, demonstrating the capability of transformers in image classification tasks. Due to computational resource limitations, the model was trained for a limited number of epochs, with the primary objective being the implementation of ViT rather than extensive hyperparameter tuning.
